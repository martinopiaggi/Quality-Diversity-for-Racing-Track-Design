{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP-Elites using pyribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import random\n",
    "from ribs.archives import GridArchive\n",
    "from ribs.emitters import EmitterBase\n",
    "from ribs.schedulers import Scheduler\n",
    "from ribs.visualize import grid_archive_heatmap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server JS which exposes the trackGenerations and genetic operators \n",
    "BASE_URL = 'http://localhost:4242'\n",
    "POINTS_COUNT = 50\n",
    "MAX_SELECTED_CELLS = 10\n",
    "SOLUTION_DIM = POINTS_COUNT * 2 + MAX_SELECTED_CELLS * 2 + 1 \n",
    "TRACK_SIZE_RANGE = (2, 5)\n",
    "LENGTH_RANGE = (400, 3000)\n",
    "\n",
    "ARCHIVE_DIM = 3;\n",
    "INIT_POPULATION = ARCHIVE_DIM * ARCHIVE_DIM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_id(iteration):\n",
    "    return iteration + random.random()\n",
    "\n",
    "def create_random_solution(iteration):\n",
    "    return {\n",
    "        \"id\": generate_id(iteration),\n",
    "        \"mode\": \"voronoi\",\n",
    "        \"dataSet\": [{\"x\": random.uniform(0, 600), \"y\": random.uniform(0, 600)} for _ in range(POINTS_COUNT)],\n",
    "        \"selectedCells\": []\n",
    "    }\n",
    "\n",
    "def solution_to_array(solution):\n",
    "    array = np.zeros(SOLUTION_DIM)\n",
    "    # Fill in dataSet\n",
    "    for i, point in enumerate(solution[\"dataSet\"]):\n",
    "        array[i*2] = point[\"x\"]\n",
    "        array[i*2 + 1] = point[\"y\"]\n",
    "    # Fill in selectedCells\n",
    "    for i, cell in enumerate(solution[\"selectedCells\"]):\n",
    "        if i < MAX_SELECTED_CELLS:\n",
    "            array[POINTS_COUNT*2 + i*2] = cell[\"x\"]\n",
    "            array[POINTS_COUNT*2 + i*2 + 1] = cell[\"y\"]\n",
    "    # Add ID at the end\n",
    "    array[-1] = solution[\"id\"]\n",
    "    return array\n",
    "\n",
    "def array_to_solution(array):\n",
    "    solution = {\n",
    "        \"id\": array[-1],\n",
    "        \"mode\": \"voronoi\",\n",
    "        \"dataSet\": [{\"x\": array[i], \"y\": array[i+1]} for i in range(0, POINTS_COUNT*2, 2)],\n",
    "        \"selectedCells\": [{\"x\": array[i], \"y\": array[i+1]} \n",
    "                          for i in range(POINTS_COUNT*2, SOLUTION_DIM-1, 2) \n",
    "                          if array[i] != 0 or array[i+1] != 0]\n",
    "    }\n",
    "    return solution\n",
    "\n",
    "def evaluate_solution(solution):\n",
    "    try:\n",
    "        response = requests.post(f'{BASE_URL}/evaluate', json=solution)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        fitness = result['fitness']\n",
    "        objective = -(fitness['deltaX'] + fitness['deltaY'])\n",
    "        measures = [result['trackSize'], fitness['length']]\n",
    "        return objective, measures, result['selectedCells']\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error in evaluate_solution: {e}\")\n",
    "        return -np.inf, [TRACK_SIZE_RANGE[0], LENGTH_RANGE[0]], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEmitter(EmitterBase):\n",
    "    def __init__(self, archive, solution_dim, batch_size=ARCHIVE_DIM, bounds=None):\n",
    "        super().__init__(archive, solution_dim=solution_dim, bounds=bounds)\n",
    "        self.batch_size = batch_size\n",
    "        self.iteration = 0\n",
    "\n",
    "    def ask(self):\n",
    "        self.iteration += 1\n",
    "        if self.iteration <= INIT_POPULATION: \n",
    "            return self.generate_initial_solutions()\n",
    "        elif np.random.random() < 0.5:  # Mutation\n",
    "            return self.mutate_solutions()\n",
    "        else:  # Crossover\n",
    "            return self.crossover_solutions()\n",
    "\n",
    "    def tell(self, solution, objective, measures, add_info, **fields):\n",
    "        # I don't need to adapt the emitter based on results ? I think\n",
    "        pass\n",
    "\n",
    "    def generate_initial_solutions(self):\n",
    "        return np.array([solution_to_array(create_random_solution(self.iteration-1)) for _ in range(self.batch_size)])\n",
    "\n",
    "    def mutate_solutions(self):\n",
    "        print(\"Mutating\")\n",
    "        parents = self.archive.sample_elites(self.batch_size)\n",
    "        mutated = []\n",
    "        for parent in parents:\n",
    "            parent_dict = array_to_solution(parent.solution, parent.metadata['id'])\n",
    "            response = requests.post(f'{BASE_URL}/mutate', json={\n",
    "                \"individual\": parent_dict,\n",
    "                \"intensityMutation\": 10\n",
    "            })\n",
    "            response.raise_for_status()\n",
    "            mutated_dict = response.json()['mutated']\n",
    "            mutated_dict['id'] = generate_id(self.iteration-1)  # Update ID for new generation\n",
    "            mutated.append(solution_to_array(mutated_dict))\n",
    "        return np.array(mutated)\n",
    "\n",
    "    def crossover_solutions(self):\n",
    "        print(\"Crossover\")\n",
    "        offspring = []\n",
    "        for _ in range(self.batch_size // 2):\n",
    "            parents = self.archive.sample_elites(2)\n",
    "            parent1 = array_to_solution(parents[0].solution)\n",
    "            parent2 = array_to_solution(parents[1].solution)\n",
    "            response = requests.post(f'{BASE_URL}/crossover', json={\n",
    "                \"mode\": \"voronoi\",\n",
    "                \"parent1\": parent1,\n",
    "                \"parent2\": parent2\n",
    "            })\n",
    "            response.raise_for_status()\n",
    "            children = response.json()['offspring']\n",
    "            for child in children:\n",
    "                child['id'] = generate_id(self.iteration-1)  # Update ID for new generation\n",
    "                offspring.append(solution_to_array(child))\n",
    "        return np.array(offspring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illuminating search spaces by mapping elites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def run_map_elites(iterations):\n",
    "    archive = GridArchive(solution_dim=SOLUTION_DIM,\n",
    "                          dims=[ARCHIVE_DIM, ARCHIVE_DIM],\n",
    "                          ranges=[TRACK_SIZE_RANGE, LENGTH_RANGE])\n",
    "\n",
    "    emitter = CustomEmitter(archive,\n",
    "                            solution_dim=SOLUTION_DIM,\n",
    "                            batch_size=INIT_POPULATION,\n",
    "                            bounds=[(0, 600)] * (SOLUTION_DIM - 1) + [(0, float('inf'))])  # Last bound is for ID\n",
    "\n",
    "    scheduler = Scheduler(archive, [emitter])\n",
    "\n",
    "    for itr in range(iterations):\n",
    "        try:\n",
    "            solution_batch = scheduler.ask()\n",
    "            \n",
    "            objectives = []\n",
    "            measures_list = []\n",
    "            updated_solutions = []\n",
    "\n",
    "            for solution in solution_batch:\n",
    "                solution_id = generate_id(itr)\n",
    "                solution[-1] = solution_id  # Set the ID in the array\n",
    "                solution_dict = array_to_solution(solution)\n",
    "                objective, measures, selected_cells = evaluate_solution(solution_dict)\n",
    "                \n",
    "                # Check if the objective is finite\n",
    "                if not np.isfinite(objective):\n",
    "                    logger.warning(f\"Non-finite objective value: {objective}. Skipping this solution.\")\n",
    "                    continue\n",
    "                \n",
    "                # Update solution with actual selectedCells\n",
    "                updated_solution = solution.copy()\n",
    "                for i, cell in enumerate(selected_cells):\n",
    "                    if i < MAX_SELECTED_CELLS:\n",
    "                        updated_solution[POINTS_COUNT*2 + i*2] = cell['x']\n",
    "                        updated_solution[POINTS_COUNT*2 + i*2 + 1] = cell['y']\n",
    "                \n",
    "                objectives.append(objective)\n",
    "                measures_list.append(measures)\n",
    "                updated_solutions.append(updated_solution)\n",
    "\n",
    "            # Only tell the scheduler if we have valid solutions\n",
    "            if objectives and measures_list:\n",
    "                scheduler.tell(objectives, measures_list)\n",
    "\n",
    "\n",
    "\n",
    "            if (itr + 1) % 10 == 0:\n",
    "                logger.info(f\"> {itr + 1} iterations completed\")\n",
    "                logger.info(f\"  - Archive size: {len(archive)}\")\n",
    "                logger.info(f\"  - Archive coverage: {archive.stats.coverage}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in iteration {itr}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_archive = run_map_elites(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "grid_archive_heatmap(final_archive)\n",
    "plt.title(\"MAP-Elites Archive\")\n",
    "plt.xlabel(\"Track Size\")\n",
    "plt.ylabel(\"Track Length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total solutions: {len(final_archive)}\")\n",
    "print(f\"Best solution: Objective = {final_archive.stats.obj_max}\")\n",
    "best_solution = final_archive.elite_with_behavior(final_archive.best)\n",
    "print(f\"Best solution measures: {best_solution.behavior}\")\n",
    "\n",
    "best_track = solution_array_to_dict(best_solution.solution, best_solution.behavior[0])\n",
    "print(\"Best track data:\", json.dumps(best_track, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
