{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP-Elites track generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import random\n",
    "from ribs.archives import GridArchive\n",
    "from ribs.emitters import EmitterBase\n",
    "from ribs.schedulers import Scheduler\n",
    "from ribs.visualize import grid_archive_heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server JS which exposes the trackGenerations and genetic operators \n",
    "BASE_URL = 'http://localhost:4242'\n",
    "POINTS_COUNT = 50\n",
    "MAX_SELECTED_CELLS = 10\n",
    "SOLUTION_DIM = POINTS_COUNT * 2 + MAX_SELECTED_CELLS * 2 + 1 \n",
    "TRACK_SIZE_RANGE = (2, 5)\n",
    "LENGTH_RANGE = (400, 2000)\n",
    "ITERATIONS = 5;\n",
    "ARCHIVE_DIM = 2;\n",
    "INIT_POPULATION = ARCHIVE_DIM * ARCHIVE_DIM \n",
    "\n",
    "\n",
    "# debug flags\n",
    "DEBUG_CROSSOVER = True\n",
    "DEBUG_MUTATION = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution(iteration):\n",
    "    response = requests.post(f'{BASE_URL}/generate', json={\n",
    "        \"id\": iteration + random.random(),\n",
    "        \"mode\": \"voronoi\",\n",
    "        \"trackSize\": random.randint(TRACK_SIZE_RANGE[0], TRACK_SIZE_RANGE[1])\n",
    "    })\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "    \n",
    "def solution_to_array(solution):\n",
    "    array = np.zeros(SOLUTION_DIM)\n",
    "    # Fill in dataSet\n",
    "    for i, point in enumerate(solution[\"dataSet\"]):\n",
    "        array[i*2] = point[\"x\"]\n",
    "        array[i*2 + 1] = point[\"y\"]\n",
    "    # Fill in selectedCells\n",
    "    for i, cell in enumerate(solution[\"selectedCells\"]):\n",
    "        if i < MAX_SELECTED_CELLS:\n",
    "            array[POINTS_COUNT*2 + i*2] = cell[\"x\"]\n",
    "            array[POINTS_COUNT*2 + i*2 + 1] = cell[\"y\"]\n",
    "    array[-1] = solution[\"id\"]\n",
    "    return array\n",
    "\n",
    "def array_to_solution(array):\n",
    "    dataSet = [{\"x\": float(array[i]), \"y\": float(array[i+1])} for i in range(0, POINTS_COUNT*2, 2)]\n",
    "    selectedCells = [{\"x\": float(array[i]), \"y\": float(array[i+1])} \n",
    "                     for i in range(POINTS_COUNT*2, SOLUTION_DIM-1, 2) \n",
    "                     if array[i] != 0 or array[i+1] != 0]\n",
    "    \n",
    "    return {\n",
    "        \"id\": float(array[-1]),\n",
    "        \"mode\": \"voronoi\",\n",
    "        \"dataSet\": dataSet,\n",
    "        \"selectedCells\": selectedCells\n",
    "    }\n",
    "\n",
    "def get_fractional_part(id_value):\n",
    "    return id_value - int(id_value)\n",
    "\n",
    "def evaluate_solution(solution):\n",
    "    try:\n",
    "        response = requests.post(f'{BASE_URL}/evaluate', json=solution)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        fitness = result['fitness']\n",
    "        objective = -(fitness['deltaX'] + fitness['deltaY'])\n",
    "        measures = [len(solution['selectedCells']), fitness['length']]\n",
    "        return objective, measures\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error in evaluate_solution: {e}\")\n",
    "        return -np.inf, [TRACK_SIZE_RANGE[0], LENGTH_RANGE[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEmitter(EmitterBase):\n",
    "    def __init__(self, archive, solution_dim, batch_size=ARCHIVE_DIM, bounds=None):\n",
    "        super().__init__(archive, solution_dim=solution_dim, bounds=bounds)\n",
    "        self.batch_size = batch_size\n",
    "        self.iteration = 0\n",
    "\n",
    "    def ask(self):\n",
    "        self.iteration += 1\n",
    "        if self.iteration <= INIT_POPULATION: \n",
    "            return np.array([solution_to_array(generate_solution(self.iteration-1)) for _ in range(self.batch_size)])\n",
    "        elif np.random.random() < 0.5:  # Mutation\n",
    "            return self.mutate_solutions()\n",
    "        else:  # Crossover\n",
    "            return self.crossover_solutions()\n",
    "\n",
    "    def generate_initial_solutions(self):\n",
    "        return np.array([solution_to_array(generate_solution(self.iteration-1)) for _ in range(self.batch_size)])\n",
    "\n",
    "\n",
    "    def mutate_solutions(self):\n",
    "        parents_data = self.archive.sample_elites(self.batch_size)\n",
    "        mutated = []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            solution = parents_data['solution'][i]\n",
    "            parent_dict = array_to_solution(solution)\n",
    "\n",
    "            response = requests.post(f'{BASE_URL}/mutate', json={\n",
    "                \"individual\": parent_dict,\n",
    "                \"intensityMutation\": 10\n",
    "            })\n",
    "            response.raise_for_status()\n",
    "            mutated_dict = response.json()['mutated']\n",
    "            \n",
    "            # Keep the same ID for mutations, just update the iteration part\n",
    "            parent_frac = get_fractional_part(parent_dict['id'])\n",
    "            mutated_dict['id'] = self.iteration - 1 + parent_frac\n",
    "            \n",
    "            mutated.append(solution_to_array(mutated_dict))\n",
    "\n",
    "        return np.array(mutated)\n",
    "\n",
    "    def crossover_solutions(self):\n",
    "        offspring = []\n",
    "        for i in range(self.batch_size // 2):\n",
    "            parents = self.archive.sample_elites(2)\n",
    "            \n",
    "            parent1 = array_to_solution(parents['solution'][0])\n",
    "            parent2 = array_to_solution(parents['solution'][1])\n",
    "            \n",
    "            response = requests.post(f'{BASE_URL}/crossover', json={\n",
    "                \"mode\": \"voronoi\",\n",
    "                \"parent1\": parent1,\n",
    "                \"parent2\": parent2\n",
    "            })\n",
    "            response.raise_for_status()\n",
    "            children = response.json()['offspring']\n",
    "            print(\"children selected \") \n",
    "            print(len(children['sel']))\n",
    "            # Create a new ID based on parents' IDs\n",
    "            parent1_frac = get_fractional_part(parent1['id'])\n",
    "            parent2_frac = get_fractional_part(parent2['id'])\n",
    "            child_frac = (parent1_frac + parent2_frac) % 1  # Ensure it's between 0 and 1\n",
    "            new_id = self.iteration - 1 + child_frac\n",
    "            \n",
    "            child = {\n",
    "                \"id\": new_id,\n",
    "                \"mode\": \"voronoi\",\n",
    "                \"trackSize\": len(children['sel']),\n",
    "                \"dataSet\": children['ds'],\n",
    "                \"selectedCells\": children['sel']\n",
    "            }\n",
    "            \n",
    "            offspring.append(solution_to_array(child))\n",
    "            if DEBUG_CROSSOVER:\n",
    "                logger.info(f\"Crossover {i+1}, Child: Parent1 ID {parent1['id']}, Parent2 ID {parent2['id']}, Child ID {new_id}\")\n",
    "        \n",
    "        return np.array(offspring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illuminating search spaces by mapping elites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_map_elites(iterations):\n",
    "    archive = GridArchive(solution_dim=SOLUTION_DIM,\n",
    "                          dims=[ARCHIVE_DIM, ARCHIVE_DIM],\n",
    "                          ranges=[TRACK_SIZE_RANGE, LENGTH_RANGE])\n",
    "\n",
    "    emitter = CustomEmitter(archive,\n",
    "                            solution_dim=SOLUTION_DIM,\n",
    "                            batch_size=INIT_POPULATION,\n",
    "                            bounds=[(0, 600)] * (SOLUTION_DIM - 1) + [(0, float('inf'))])\n",
    "\n",
    "    scheduler = Scheduler(archive, [emitter])\n",
    "\n",
    "    for itr in range(iterations):\n",
    "        try:\n",
    "            solution_batch = scheduler.ask()\n",
    "            \n",
    "            objectives = []\n",
    "            measures_list = []\n",
    "            updated_solutions = []\n",
    "\n",
    "            for solution_array in solution_batch:\n",
    "                solution = array_to_solution(solution_array)\n",
    "                objective, measures = evaluate_solution(solution)\n",
    "                \n",
    "                if not np.isfinite(objective):\n",
    "                    logger.warning(f\"Non-finite objective value: {objective}. Skipping this solution.\")\n",
    "                    continue\n",
    "                \n",
    "                objectives.append(objective)\n",
    "                measures_list.append(measures)\n",
    "\n",
    "            if objectives and measures_list:\n",
    "                print(f\"Before tell: Archive size = {len(archive)}\")\n",
    "                scheduler.tell(objectives, measures_list)\n",
    "                print(f\"After tell: Archive size = {len(archive)}\")\n",
    "                print(f\"Objectives: {objectives}\")\n",
    "                print(f\"Measures: {measures_list}\")\n",
    "            else:\n",
    "                logger.warning(f\"Iteration {itr + 1}: No valid solutions to add to archive\")\n",
    "\n",
    "            logger.info(f\"> {itr + 1} iterations completed\")\n",
    "            logger.info(f\"  - Archive size: {len(archive)}\")\n",
    "            logger.info(f\"  - Archive coverage: {archive.stats.coverage}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in iteration {itr}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before tell: Archive size = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:> 1 iterations completed\n",
      "INFO:__main__:  - Archive size: 2\n",
      "INFO:__main__:  - Archive coverage: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After tell: Archive size = 2\n",
      "Objectives: [-1.8352849999999998, -3.642106, -1.0809630000000001, -1.6500850000000002]\n",
      "Measures: [[5, 1150.20459], [5, 1328.702148], [5, 1090.650635], [5, 1255.467407]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Non-finite objective value: -inf. Skipping this solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in evaluate_solution: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Non-finite objective value: -inf. Skipping this solution.\n",
      "ERROR:__main__:Error in iteration 1: objective should have length 4 (this is the number of solutions output by ask()) but has length 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in evaluate_solution: HTTPConnectionPool(host='localhost', port=4242): Max retries exceeded with url: /evaluate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000021CB6003ED0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "Before tell: Archive size = 2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "objective should have length 4 (this is the number of solutions output by ask()) but has length 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m final_archive \u001b[38;5;241m=\u001b[39m \u001b[43mrun_map_elites\u001b[49m\u001b[43m(\u001b[49m\u001b[43mITERATIONS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 34\u001b[0m, in \u001b[0;36mrun_map_elites\u001b[1;34m(iterations)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m objectives \u001b[38;5;129;01mand\u001b[39;00m measures_list:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBefore tell: Archive size = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(archive)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     \u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjectives\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasures_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter tell: Archive size = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(archive)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjectives: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobjectives\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ribs\\schedulers\\_scheduler.py:360\u001b[0m, in \u001b[0;36mScheduler.tell\u001b[1;34m(self, objective, measures, **fields)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtell() was called without calling ask().\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtell\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 360\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tell_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobjective\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeasures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    366\u001b[0m add_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_to_archives(data)\n\u001b[0;32m    368\u001b[0m \u001b[38;5;66;03m# Keep track of pos because emitters may have different batch sizes.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ribs\\schedulers\\_scheduler.py:222\u001b[0m, in \u001b[0;36mScheduler._validate_tell_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, arr \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    221\u001b[0m     data[name] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# Convenient to have solutions be part of data, so that everything is\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# just one dict.\u001b[39;00m\n\u001b[0;32m    226\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolution\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_solutions\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ribs\\schedulers\\_scheduler.py:213\u001b[0m, in \u001b[0;36mScheduler._check_length\u001b[1;34m(self, name, arr)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Raises a ValueError if array does not have the same length as the\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03msolutions.\"\"\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(arr) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_solutions):\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should have length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_solutions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(this is the number of solutions output by ask()) but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(arr)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: objective should have length 4 (this is the number of solutions output by ask()) but has length 2"
     ]
    }
   ],
   "source": [
    "final_archive = run_map_elites(ITERATIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "grid_archive_heatmap(final_archive)\n",
    "plt.title(\"MAP-Elites Archive\")\n",
    "plt.xlabel(\"Track Size\")\n",
    "plt.ylabel(\"Track Length\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
